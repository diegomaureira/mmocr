{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "main_path = '/home/diego/Documents/MLCDataset_v1/txts/Label*.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_paths = sorted(glob.glob(main_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/diego/Documents/MLCDataset_v1/txts/Label_0.txt', '/home/diego/Documents/MLCDataset_v1/txts/Label_1.txt', '/home/diego/Documents/MLCDataset_v1/txts/Label_10.txt', '/home/diego/Documents/MLCDataset_v1/txts/Label_11.txt', '/home/diego/Documents/MLCDataset_v1/txts/Label_12.txt', '/home/diego/Documents/MLCDataset_v1/txts/Label_13.txt', '/home/diego/Documents/MLCDataset_v1/txts/Label_14.txt', '/home/diego/Documents/MLCDataset_v1/txts/Label_2.txt', '/home/diego/Documents/MLCDataset_v1/txts/Label_3.txt', '/home/diego/Documents/MLCDataset_v1/txts/Label_4.txt', '/home/diego/Documents/MLCDataset_v1/txts/Label_5.txt', '/home/diego/Documents/MLCDataset_v1/txts/Label_6.txt', '/home/diego/Documents/MLCDataset_v1/txts/Label_7.txt', '/home/diego/Documents/MLCDataset_v1/txts/Label_8.txt', '/home/diego/Documents/MLCDataset_v1/txts/Label_9.txt']\n"
     ]
    }
   ],
   "source": [
    "print(txt_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_txt_files(txt_paths, output_path):\n",
    "    temp_names = []\n",
    "    with open(output_path, 'w') as outfile:\n",
    "        for txt_path in txt_paths:\n",
    "            with open(txt_path) as infile:\n",
    "                for line in infile:\n",
    "                    name = line.split('\t')[0]\n",
    "                    if name not in temp_names:\n",
    "                        temp_names.append(name)\n",
    "                        outfile.write(line)\n",
    "    return len(temp_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    }
   ],
   "source": [
    "#for i in range(0, len(txt_paths)):\n",
    "#    print(txt_paths[i])\n",
    "#    c = join_txt_files([txt_paths[i]], '/home/diego/Documents/MLCDataset_v1/merged.txt')\n",
    "#    print(c)\n",
    "#    break\n",
    "len_names = join_txt_files(txt_paths, '/home/diego/Documents/MLCDataset_v1/merged.txt')\n",
    "print(len_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/diego/Documents/MLCDataset_v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/203 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 110.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total text format has been written to individual text files in the output directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tqdm\n",
    "\n",
    "# Function to parse the input text file and convert it to Total Text format\n",
    "def convert_to_total_text_format(input_file, output_img_dir, output_dir):\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(output_img_dir, exist_ok=True)\n",
    "\n",
    "    input_dir_path = os.path.dirname(input_file)\n",
    "    print(input_dir_path)\n",
    "\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "        for idx, line in enumerate(tqdm.tqdm(lines)):\n",
    "            try:\n",
    "                # Split each line into image name and annotations\n",
    "                parts = line.strip().split('\t', 1)\n",
    "                if len(parts) < 2:\n",
    "                    continue  # Skip lines that don't have annotations\n",
    "\n",
    "                image_name = parts[0].split('/')[-1]\n",
    "                global_image_name = input_dir_path + '/' + image_name\n",
    "                # copy image to output directory\n",
    "                new_name = \"img{}.jpg\".format(idx)\n",
    "                os.system(\"cp {} {}\".format(global_image_name, output_img_dir + new_name))\n",
    "                annotations = eval(parts[1].replace(\"false\", \"False\"))  # Use eval carefully; ensure input is safe\n",
    "\n",
    "                # Create a filename for the output text file based on the image name\n",
    "                #filename_without_extension = os.path.splitext(image_name)[0]\n",
    "                output_file_path = os.path.join(output_dir, new_name.replace('.jpg', '.txt'))\n",
    "\n",
    "                with open(output_file_path, 'w', encoding='utf-8') as f_out:\n",
    "                    for annotation in annotations:\n",
    "                        transcription = annotation[\"transcription\"]\n",
    "                        if \"'\" in transcription:\n",
    "                            transcription = transcription.replace(\"'\", \"\")\n",
    "                        if \",\":\n",
    "                            transcription = transcription.replace(\",\", \"\") \n",
    "                        points = annotation[\"points\"]\n",
    "                        if \"?\" in transcription:\n",
    "                            transcription = transcription.replace(\"?\", \"\")\n",
    "                        if \"\\\\\" in transcription:\n",
    "                            transcription = transcription.replace(\"\\\\\", \"\")\n",
    "                        if \"/\" in transcription:\n",
    "                            transcription = transcription.replace(\"/\", \"\")\n",
    "                        if \"[\" in transcription:\n",
    "                            transcription = transcription.replace(\"[\", \"\")\n",
    "                        if \"]\" in transcription:\n",
    "                            transcription = transcription.replace(\"]\", \"\")\n",
    "                        # Extract x and y coordinates\n",
    "                        x_coords = [int(point[0]) for point in points]\n",
    "                        y_coords = [int(point[1]) for point in points]\n",
    "\n",
    "                        # Define orientation (example: 'c' for centered text)\n",
    "                        orientation = 'c'  # You can change this logic based on your needs\n",
    "\n",
    "                        # Create the entry for Total Text format\n",
    "                        entry = (\n",
    "                            f\"x: [{x_coords}], \"\n",
    "                            f\"y: [{y_coords}], \"\n",
    "                            f\"ornt: [u'{orientation}'], \"\n",
    "                            f\"transcriptions: [u'{transcription}']\"\n",
    "                        )\n",
    "\n",
    "                        # Write each entry to the respective output file\n",
    "                        f_out.write(f\"{entry}\\n\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "# Specify input and output files\n",
    "input_file_path = '/home/diego/Documents/MLCDataset_v1/merged.txt'  # Replace with your actual input file path\n",
    "output_img_dir_path = '/home/diego/Documents/MLCDataset_v1/textdet_imgs/test/'  # Directory where images will be saved\n",
    "output_directory_path = '/home/diego/Documents/MLCDataset_v1/annotations/test/'  # Directory where output files will be saved\n",
    "\n",
    "# Call the conversion function\n",
    "convert_to_total_text_format(input_file_path, output_img_dir_path,output_directory_path)\n",
    "\n",
    "print(\"Total text format has been written to individual text files in the output directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33;40mDataset Name: Total Text\n",
      "License Type: BSD-3\n",
      "License Link: https://github.com/cs-chan/Total-Text-Dataset/blob/master/LICENSE\n",
      "BibTeX: @article{CK2019, author = {Chee Kheng Chng and Chee Seng Chan and Chenglin Liu}, title = {Total-Text: Towards Orientation Robustness in Scene Text Detection}, journal = {International Journal on Document Analysis and Recognition (IJDAR)}, volume = {23}, pages = {31-52}, year = {2020}, doi = {10.1007/s10032-019-00334-z}}\u001b[0m\n",
      "\u001b[1;31;43mMMOCR does not own the dataset. Using this dataset you must accept the license provided by the owners, and cite the corresponding papers appropriately.\n",
      "If you do not agree with the above license, please cancel the progress immediately by pressing ctrl+c. Otherwise, you are deemed to accept the terms and conditions.\u001b[0m\n",
      "5...\n",
      "4...\n",
      "3...\n",
      "2...\n",
      "1...\n",
      "Gathering test Dataset...\n",
      "Parsing test Images and Annotations...\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 203/203, 195.5 task/s, elapsed: 1s, ETA:     0s\n",
      "Packing test Annotations...\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 203/203, 251.3 task/s, elapsed: 1s, ETA:     0s\n",
      "Dumping test Annotations...\n",
      "Generating base configs...\n"
     ]
    }
   ],
   "source": [
    "!python tools/dataset_converters/prepare_dataset.py paddleann --task textrecog --overwrite-cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/diego/p_workspace/mo/lib/python3.8/site-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n",
      "[>                               ] 10/203, 1.3 task/s, elapsed: 7s, ETA:   144s^C\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/visualizations/browse_dataset.py\", line 415, in <module>\n",
      "    main()\n",
      "  File \"tools/visualizations/browse_dataset.py\", line 381, in main\n",
      "    image_show = visualizer.add_datasample(\n",
      "  File \"/home/diego/p_workspace/mmocr/mmocr/visualization/textdet_visualizer.py\", line 194, in add_datasample\n",
      "    return self.get_image()\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/mmengine/dist/utils.py\", line 427, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/mmengine/visualization/visualizer.py\", line 316, in get_image\n",
      "    return img_from_canvas(self.fig_save_canvas)  # type: ignore\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/mmengine/visualization/utils.py\", line 240, in img_from_canvas\n",
      "    s, (width, height) = canvas.print_to_buffer()\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py\", line 512, in print_to_buffer\n",
      "    FigureCanvasAgg.draw(self)\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py\", line 400, in draw\n",
      "    self.figure.draw(self.renderer)\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/matplotlib/artist.py\", line 95, in draw_wrapper\n",
      "    result = draw(artist, renderer, *args, **kwargs)\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/matplotlib/artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/matplotlib/figure.py\", line 3175, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/matplotlib/image.py\", line 131, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/matplotlib/artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/matplotlib/axes/_base.py\", line 3064, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/matplotlib/image.py\", line 131, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/matplotlib/artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/matplotlib/image.py\", line 641, in draw\n",
      "    im, l, b, trans = self.make_image(\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/matplotlib/image.py\", line 949, in make_image\n",
      "    return self._make_image(self._A, bbox, transformed_bbox, clip,\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/matplotlib/image.py\", line 555, in _make_image\n",
      "    output = _resample(  # resample rgb channels\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/matplotlib/image.py\", line 207, in _resample\n",
      "    _image.resample(data, out, transform,\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python tools/visualizations/browse_dataset.py configs/textdet/_base_/datasets/paddleann.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/08 14:38:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.8.20 (default, Sep  7 2024, 18:35:07) [GCC 13.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 583437386\n",
      "    GPU 0: NVIDIA GeForce GTX 1650\n",
      "    CUDA_HOME: /usr\n",
      "    NVCC: Cuda compilation tools, release 12.0, V12.0.140\n",
      "    GCC: x86_64-linux-gnu-gcc (Ubuntu 13.2.0-23ubuntu4) 13.2.0\n",
      "    PyTorch: 1.10.0+cu111\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.0.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "    TorchVision: 0.11.0+cu111\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 583437386\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "11/08 14:38:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=4)\n",
      "ctw1500_textdet_test = dict(\n",
      "    ann_file='textdet_test.json',\n",
      "    data_root='data/paddleann',\n",
      "    pipeline=[\n",
      "        dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),\n",
      "        dict(keep_ratio=True, scale=(\n",
      "            1333,\n",
      "            736,\n",
      "        ), type='Resize'),\n",
      "        dict(\n",
      "            type='LoadOCRAnnotations',\n",
      "            with_bbox=True,\n",
      "            with_label=True,\n",
      "            with_polygon=True),\n",
      "        dict(\n",
      "            meta_keys=(\n",
      "                'img_path',\n",
      "                'ori_shape',\n",
      "                'img_shape',\n",
      "                'scale_factor',\n",
      "            ),\n",
      "            type='PackTextDetInputs'),\n",
      "    ],\n",
      "    test_mode=True,\n",
      "    type='OCRDataset')\n",
      "ctw1500_textdet_train = dict(\n",
      "    ann_file='textdet_test.json',\n",
      "    data_root='data/paddleann',\n",
      "    pipeline=[\n",
      "        dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),\n",
      "        dict(keep_ratio=True, scale=(\n",
      "            1333,\n",
      "            736,\n",
      "        ), type='Resize'),\n",
      "        dict(\n",
      "            type='LoadOCRAnnotations',\n",
      "            with_bbox=True,\n",
      "            with_label=True,\n",
      "            with_polygon=True),\n",
      "        dict(\n",
      "            meta_keys=(\n",
      "                'img_path',\n",
      "                'ori_shape',\n",
      "                'img_shape',\n",
      "                'scale_factor',\n",
      "            ),\n",
      "            type='PackTextDetInputs'),\n",
      "    ],\n",
      "    test_mode=True,\n",
      "    type='OCRDataset')\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=20, type='CheckpointHook'),\n",
      "    logger=dict(interval=5, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffer=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(\n",
      "        draw_gt=False,\n",
      "        draw_pred=False,\n",
      "        enable=False,\n",
      "        interval=1,\n",
      "        show=False,\n",
      "        type='VisualizationHook'))\n",
      "default_scope = 'mmocr'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "launcher = 'none'\n",
      "load_from = 'weights/textsnake_resnet50-oclip_fpn-unet_1200e_ctw1500_20221101_134814-a216e5b2.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=10)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmocr/backbone/resnet50-oclip-7ba0c533.pth',\n",
      "            type='Pretrained'),\n",
      "        type='CLIPResNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='TextDetDataPreprocessor'),\n",
      "    det_head=dict(\n",
      "        in_channels=32,\n",
      "        module_loss=dict(type='TextSnakeModuleLoss'),\n",
      "        postprocessor=dict(\n",
      "            text_repr_type='poly', type='TextSnakePostprocessor'),\n",
      "        type='TextSnakeHead'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ], out_channels=32, type='FPN_UNet'),\n",
      "    type='TextSnake')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.007, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
      "    type='OptimWrapper')\n",
      "paddleann_textdet_data_root = 'data/paddleann'\n",
      "paddleann_textdet_test = dict(\n",
      "    ann_file='textdet_test.json',\n",
      "    data_root='data/paddleann',\n",
      "    pipeline=[\n",
      "        dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),\n",
      "        dict(keep_ratio=True, scale=(\n",
      "            1333,\n",
      "            736,\n",
      "        ), type='Resize'),\n",
      "        dict(\n",
      "            type='LoadOCRAnnotations',\n",
      "            with_bbox=True,\n",
      "            with_label=True,\n",
      "            with_polygon=True),\n",
      "        dict(\n",
      "            meta_keys=(\n",
      "                'img_path',\n",
      "                'ori_shape',\n",
      "                'img_shape',\n",
      "                'scale_factor',\n",
      "            ),\n",
      "            type='PackTextDetInputs'),\n",
      "    ],\n",
      "    test_mode=True,\n",
      "    type='OCRDataset')\n",
      "paddleann_textdet_train = dict(\n",
      "    ann_file='textdet_test.json',\n",
      "    data_root='data/paddleann',\n",
      "    filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "    pipeline=None,\n",
      "    type='OCRDataset')\n",
      "param_scheduler = [\n",
      "    dict(end=1200, eta_min=1e-07, power=0.9, type='PolyLR'),\n",
      "]\n",
      "randomness = dict(seed=None)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='textdet_test.json',\n",
      "        data_root='data/paddleann',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                color_type='color_ignore_orientation',\n",
      "                type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                736,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                type='LoadOCRAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_label=True,\n",
      "                with_polygon=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackTextDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='OCRDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(type='HmeanIOUMetric')\n",
      "test_pipeline = [\n",
      "    dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        736,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        type='LoadOCRAnnotations',\n",
      "        with_bbox=True,\n",
      "        with_label=True,\n",
      "        with_polygon=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackTextDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1200, type='EpochBasedTrainLoop', val_interval=20)\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file='textdet_test.json',\n",
      "        data_root='data/paddleann',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                color_type='color_ignore_orientation',\n",
      "                type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                736,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                type='LoadOCRAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_label=True,\n",
      "                with_polygon=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackTextDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='OCRDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='LoadOCRAnnotations',\n",
      "        with_bbox=True,\n",
      "        with_label=True,\n",
      "        with_polygon=True),\n",
      "    dict(\n",
      "        brightness=0.12549019607843137,\n",
      "        op='ColorJitter',\n",
      "        saturation=0.5,\n",
      "        type='TorchVisionWrapper'),\n",
      "    dict(\n",
      "        prob=0.65,\n",
      "        transforms=[\n",
      "            dict(min_side_ratio=0.3, type='RandomCrop'),\n",
      "        ],\n",
      "        type='RandomApply'),\n",
      "    dict(\n",
      "        max_angle=20,\n",
      "        pad_with_fixed_color=False,\n",
      "        type='RandomRotate',\n",
      "        use_canvas=True),\n",
      "    dict(\n",
      "        aspect_ratio_range=(\n",
      "            0.9,\n",
      "            1.1,\n",
      "        ),\n",
      "        long_size_bound=800,\n",
      "        ratio_range=(\n",
      "            0.7,\n",
      "            1.3,\n",
      "        ),\n",
      "        short_size_bound=480,\n",
      "        type='BoundedScaleAspectJitter'),\n",
      "    dict(\n",
      "        prob=[\n",
      "            0.4,\n",
      "            0.6,\n",
      "        ],\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale=800, type='Resize'),\n",
      "                dict(target_scale=800, type='SourceImagePad'),\n",
      "            ],\n",
      "            dict(keep_ratio=False, scale=800, type='Resize'),\n",
      "        ],\n",
      "        type='RandomChoice'),\n",
      "    dict(direction='horizontal', prob=0.5, type='RandomFlip'),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "        ),\n",
      "        type='PackTextDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='textdet_test.json',\n",
      "        data_root='data/paddleann',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                color_type='color_ignore_orientation',\n",
      "                type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                736,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                type='LoadOCRAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_label=True,\n",
      "                with_polygon=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackTextDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='OCRDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(type='HmeanIOUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='TextDetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/textsnake_resnet50-oclip_fpn-unet_1200e_mine'\n",
      "\n",
      "11/08 14:38:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "11/08 14:38:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: weights/textsnake_resnet50-oclip_fpn-unet_1200e_ctw1500_20221101_134814-a216e5b2.pth\n",
      "11/08 14:38:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from weights/textsnake_resnet50-oclip_fpn-unet_1200e_ctw1500_20221101_134814-a216e5b2.pth\n",
      "11/08 14:38:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [  5/203]    eta: 0:03:38  time: 1.1046  data_time: 0.0606  memory: 996  \n",
      "11/08 14:38:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 10/203]    eta: 0:02:48  time: 0.8746  data_time: 0.0325  memory: 996  \n",
      "11/08 14:38:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 15/203]    eta: 0:02:36  time: 0.6962  data_time: 0.0037  memory: 1002  \n",
      "11/08 14:38:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 20/203]    eta: 0:02:33  time: 0.8021  data_time: 0.0034  memory: 996  \n",
      "11/08 14:38:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 25/203]    eta: 0:02:50  time: 1.1428  data_time: 0.0040  memory: 1011  \n",
      "11/08 14:38:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 30/203]    eta: 0:02:34  time: 0.9990  data_time: 0.0034  memory: 987  \n",
      "11/08 14:38:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 35/203]    eta: 0:02:26  time: 0.6564  data_time: 0.0029  memory: 996  \n",
      "11/08 14:39:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 40/203]    eta: 0:02:29  time: 1.0035  data_time: 0.0031  memory: 1011  \n",
      "11/08 14:39:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 45/203]    eta: 0:02:33  time: 1.3194  data_time: 0.0033  memory: 1003  \n",
      "11/08 14:39:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 50/203]    eta: 0:02:30  time: 1.2350  data_time: 0.0043  memory: 996  \n",
      "11/08 14:39:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 55/203]    eta: 0:02:29  time: 1.1952  data_time: 0.0040  memory: 1011  \n",
      "11/08 14:39:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 60/203]    eta: 0:02:29  time: 1.3495  data_time: 0.0034  memory: 1011  \n",
      "11/08 14:39:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 65/203]    eta: 0:02:23  time: 1.2094  data_time: 0.0034  memory: 1003  \n",
      "11/08 14:39:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 70/203]    eta: 0:02:15  time: 0.8751  data_time: 0.0029  memory: 542  \n",
      "11/08 14:39:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 75/203]    eta: 0:02:12  time: 0.9684  data_time: 0.0032  memory: 998  \n",
      "11/08 14:39:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 80/203]    eta: 0:02:12  time: 1.4970  data_time: 0.0038  memory: 996  \n",
      "11/08 14:39:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 85/203]    eta: 0:02:06  time: 1.3935  data_time: 0.0036  memory: 1011  \n",
      "11/08 14:40:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 90/203]    eta: 0:01:59  time: 0.8907  data_time: 0.0037  memory: 996  \n",
      "11/08 14:40:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 95/203]    eta: 0:01:52  time: 0.7860  data_time: 0.0039  memory: 996  \n",
      "11/08 14:40:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [100/203]    eta: 0:01:46  time: 0.8443  data_time: 0.0035  memory: 996  \n",
      "11/08 14:40:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [105/203]    eta: 0:01:40  time: 0.8690  data_time: 0.0032  memory: 996  \n",
      "11/08 14:40:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [110/203]    eta: 0:01:34  time: 0.7974  data_time: 0.0036  memory: 996  \n",
      "11/08 14:40:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [115/203]    eta: 0:01:27  time: 0.6969  data_time: 0.0038  memory: 917  \n",
      "11/08 14:40:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [120/203]    eta: 0:01:22  time: 0.7173  data_time: 0.0038  memory: 996  \n",
      "11/08 14:40:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [125/203]    eta: 0:01:17  time: 0.9432  data_time: 0.0042  memory: 996  \n",
      "11/08 14:40:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [130/203]    eta: 0:01:13  time: 1.2838  data_time: 0.0040  memory: 998  \n",
      "11/08 14:40:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [135/203]    eta: 0:01:08  time: 1.2257  data_time: 0.0037  memory: 996  \n",
      "11/08 14:40:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [140/203]    eta: 0:01:03  time: 1.0292  data_time: 0.0037  memory: 1007  \n",
      "11/08 14:40:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [145/203]    eta: 0:00:58  time: 1.0243  data_time: 0.0036  memory: 1003  \n",
      "11/08 14:41:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [150/203]    eta: 0:00:54  time: 1.1286  data_time: 0.0034  memory: 996  \n",
      "11/08 14:41:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [155/203]    eta: 0:00:49  time: 1.2635  data_time: 0.0034  memory: 488  \n",
      "11/08 14:41:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [160/203]    eta: 0:00:44  time: 1.1417  data_time: 0.0036  memory: 996  \n",
      "11/08 14:41:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [165/203]    eta: 0:00:38  time: 0.8520  data_time: 0.0035  memory: 542  \n",
      "11/08 14:41:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [170/203]    eta: 0:00:33  time: 0.9123  data_time: 0.0036  memory: 554  \n",
      "11/08 14:41:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [175/203]    eta: 0:00:28  time: 0.9101  data_time: 0.0037  memory: 996  \n",
      "11/08 14:41:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [180/203]    eta: 0:00:23  time: 1.1315  data_time: 0.0037  memory: 994  \n",
      "11/08 14:41:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [185/203]    eta: 0:00:18  time: 1.3240  data_time: 0.0033  memory: 998  \n",
      "11/08 14:41:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [190/203]    eta: 0:00:13  time: 0.9715  data_time: 0.0035  memory: 1002  \n",
      "11/08 14:41:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [195/203]    eta: 0:00:08  time: 0.9628  data_time: 0.0034  memory: 996  \n",
      "11/08 14:41:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [200/203]    eta: 0:00:03  time: 1.0104  data_time: 0.0032  memory: 1007  \n",
      "11/08 14:41:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating hmean-iou...\n",
      "11/08 14:41:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.30, recall: 0.1622, precision: 0.3498, hmean: 0.2216\n",
      "\n",
      "11/08 14:41:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.40, recall: 0.1601, precision: 0.3708, hmean: 0.2237\n",
      "\n",
      "11/08 14:41:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.50, recall: 0.1579, precision: 0.3858, hmean: 0.2241\n",
      "\n",
      "11/08 14:41:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.60, recall: 0.1534, precision: 0.3975, hmean: 0.2214\n",
      "\n",
      "11/08 14:41:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.70, recall: 0.1432, precision: 0.3991, hmean: 0.2107\n",
      "\n",
      "11/08 14:41:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.80, recall: 0.1174, precision: 0.3911, hmean: 0.1806\n",
      "\n",
      "11/08 14:41:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.90, recall: 0.0133, precision: 0.1755, hmean: 0.0247\n",
      "\n",
      "11/08 14:41:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [203/203]    icdar/precision: 0.3858  icdar/recall: 0.1579  icdar/hmean: 0.2241  data_time: 0.0050  time: 1.0239\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python tools/test.py configs/textdet/textsnake/textsnake_resnet50-oclip_fpn-unet_1200e_mine.py \\\n",
    "                                             weights/textsnake_resnet50-oclip_fpn-unet_1200e_ctw1500_20221101_134814-a216e5b2.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/08 16:45:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.8.20 (default, Sep  7 2024, 18:35:07) [GCC 13.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 648317817\n",
      "    GPU 0: NVIDIA GeForce GTX 1650\n",
      "    CUDA_HOME: /usr\n",
      "    NVCC: Cuda compilation tools, release 12.0, V12.0.140\n",
      "    GCC: x86_64-linux-gnu-gcc (Ubuntu 13.2.0-23ubuntu4) 13.2.0\n",
      "    PyTorch: 1.10.0+cu111\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.0.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "    TorchVision: 0.11.0+cu111\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 648317817\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "11/08 16:45:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=8)\n",
      "ctw1500_textdet_data_root = 'data/paddleann'\n",
      "ctw1500_textdet_test = dict(\n",
      "    ann_file='textdet_test.json',\n",
      "    data_root='data/paddleann',\n",
      "    pipeline=[\n",
      "        dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),\n",
      "        dict(keep_ratio=True, scale=(\n",
      "            1080,\n",
      "            736,\n",
      "        ), type='Resize'),\n",
      "        dict(\n",
      "            type='LoadOCRAnnotations',\n",
      "            with_bbox=True,\n",
      "            with_label=True,\n",
      "            with_polygon=True),\n",
      "        dict(\n",
      "            meta_keys=(\n",
      "                'img_path',\n",
      "                'ori_shape',\n",
      "                'img_shape',\n",
      "                'scale_factor',\n",
      "            ),\n",
      "            type='PackTextDetInputs'),\n",
      "    ],\n",
      "    test_mode=True,\n",
      "    type='OCRDataset')\n",
      "ctw1500_textdet_train = dict(\n",
      "    ann_file='textdet_test.json',\n",
      "    data_root='data/paddleann',\n",
      "    filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "    pipeline=[\n",
      "        dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),\n",
      "        dict(\n",
      "            type='LoadOCRAnnotations',\n",
      "            with_bbox=True,\n",
      "            with_label=True,\n",
      "            with_polygon=True),\n",
      "        dict(\n",
      "            keep_ratio=True,\n",
      "            ratio_range=(\n",
      "                0.75,\n",
      "                2.5,\n",
      "            ),\n",
      "            scale=(\n",
      "                800,\n",
      "                800,\n",
      "            ),\n",
      "            type='RandomResize'),\n",
      "        dict(\n",
      "            crop_ratio=0.5,\n",
      "            iter_num=1,\n",
      "            min_area_ratio=0.2,\n",
      "            type='TextDetRandomCropFlip'),\n",
      "        dict(\n",
      "            prob=0.8,\n",
      "            transforms=[\n",
      "                dict(min_side_ratio=0.3, type='RandomCrop'),\n",
      "            ],\n",
      "            type='RandomApply'),\n",
      "        dict(\n",
      "            prob=0.5,\n",
      "            transforms=[\n",
      "                dict(\n",
      "                    max_angle=30,\n",
      "                    pad_with_fixed_color=False,\n",
      "                    type='RandomRotate',\n",
      "                    use_canvas=True),\n",
      "            ],\n",
      "            type='RandomApply'),\n",
      "        dict(\n",
      "            prob=[\n",
      "                0.6,\n",
      "                0.4,\n",
      "            ],\n",
      "            transforms=[\n",
      "                [\n",
      "                    dict(keep_ratio=True, scale=800, type='Resize'),\n",
      "                    dict(target_scale=800, type='SourceImagePad'),\n",
      "                ],\n",
      "                dict(keep_ratio=False, scale=800, type='Resize'),\n",
      "            ],\n",
      "            type='RandomChoice'),\n",
      "        dict(direction='horizontal', prob=0.5, type='RandomFlip'),\n",
      "        dict(\n",
      "            brightness=0.12549019607843137,\n",
      "            contrast=0.5,\n",
      "            op='ColorJitter',\n",
      "            saturation=0.5,\n",
      "            type='TorchVisionWrapper'),\n",
      "        dict(\n",
      "            meta_keys=(\n",
      "                'img_path',\n",
      "                'ori_shape',\n",
      "                'img_shape',\n",
      "                'scale_factor',\n",
      "            ),\n",
      "            type='PackTextDetInputs'),\n",
      "    ],\n",
      "    type='OCRDataset')\n",
      "ctw_test_pipeline = [\n",
      "    dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1080,\n",
      "        736,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        type='LoadOCRAnnotations',\n",
      "        with_bbox=True,\n",
      "        with_label=True,\n",
      "        with_polygon=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackTextDetInputs'),\n",
      "]\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=20, type='CheckpointHook'),\n",
      "    logger=dict(interval=5, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffer=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(\n",
      "        draw_gt=False,\n",
      "        draw_pred=False,\n",
      "        enable=False,\n",
      "        interval=1,\n",
      "        show=False,\n",
      "        type='VisualizationHook'))\n",
      "default_scope = 'mmocr'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "launcher = 'none'\n",
      "load_from = 'weights/fcenet_resnet50-oclip_fpn_1500e_ctw1500_20221102_121909-101df7e6.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=10)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmocr/backbone/resnet50-oclip-7ba0c533.pth',\n",
      "            type='Pretrained'),\n",
      "        out_indices=(\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        type='CLIPResNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='TextDetDataPreprocessor'),\n",
      "    det_head=dict(\n",
      "        fourier_degree=5,\n",
      "        in_channels=256,\n",
      "        module_loss=dict(\n",
      "            level_proportion_range=(\n",
      "                (\n",
      "                    0,\n",
      "                    0.25,\n",
      "                ),\n",
      "                (\n",
      "                    0.2,\n",
      "                    0.65,\n",
      "                ),\n",
      "                (\n",
      "                    0.55,\n",
      "                    1.0,\n",
      "                ),\n",
      "            ),\n",
      "            num_sample=50,\n",
      "            type='FCEModuleLoss'),\n",
      "        postprocessor=dict(\n",
      "            alpha=1.0,\n",
      "            beta=2.0,\n",
      "            num_reconstr_points=50,\n",
      "            scales=(\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ),\n",
      "            score_thr=0.3,\n",
      "            text_repr_type='poly',\n",
      "            type='FCEPostprocessor'),\n",
      "        type='FCEHead'),\n",
      "    neck=dict(\n",
      "        act_cfg=None,\n",
      "        add_extra_convs='on_output',\n",
      "        in_channels=[\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=3,\n",
      "        out_channels=256,\n",
      "        relu_before_extra_convs=True,\n",
      "        type='mmdet.FPN'),\n",
      "    type='FCENet')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.0005, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(end=1500, eta_min=1e-07, power=0.9, type='PolyLR'),\n",
      "]\n",
      "randomness = dict(seed=None)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='textdet_test.json',\n",
      "        data_root='data/paddleann',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                color_type='color_ignore_orientation',\n",
      "                type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1080,\n",
      "                736,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                type='LoadOCRAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_label=True,\n",
      "                with_polygon=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackTextDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='OCRDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(type='HmeanIOUMetric')\n",
      "test_pipeline = [\n",
      "    dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2260,\n",
      "        2260,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        type='LoadOCRAnnotations',\n",
      "        with_bbox=True,\n",
      "        with_label=True,\n",
      "        with_polygon=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackTextDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1500, type='EpochBasedTrainLoop', val_interval=20)\n",
      "train_dataloader = dict(\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file='textdet_test.json',\n",
      "        data_root='data/paddleann',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                color_type='color_ignore_orientation',\n",
      "                type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='LoadOCRAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_label=True,\n",
      "                with_polygon=True),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.75,\n",
      "                    2.5,\n",
      "                ),\n",
      "                scale=(\n",
      "                    800,\n",
      "                    800,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                crop_ratio=0.5,\n",
      "                iter_num=1,\n",
      "                min_area_ratio=0.2,\n",
      "                type='TextDetRandomCropFlip'),\n",
      "            dict(\n",
      "                prob=0.8,\n",
      "                transforms=[\n",
      "                    dict(min_side_ratio=0.3, type='RandomCrop'),\n",
      "                ],\n",
      "                type='RandomApply'),\n",
      "            dict(\n",
      "                prob=0.5,\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        max_angle=30,\n",
      "                        pad_with_fixed_color=False,\n",
      "                        type='RandomRotate',\n",
      "                        use_canvas=True),\n",
      "                ],\n",
      "                type='RandomApply'),\n",
      "            dict(\n",
      "                prob=[\n",
      "                    0.6,\n",
      "                    0.4,\n",
      "                ],\n",
      "                transforms=[\n",
      "                    [\n",
      "                        dict(keep_ratio=True, scale=800, type='Resize'),\n",
      "                        dict(target_scale=800, type='SourceImagePad'),\n",
      "                    ],\n",
      "                    dict(keep_ratio=False, scale=800, type='Resize'),\n",
      "                ],\n",
      "                type='RandomChoice'),\n",
      "            dict(direction='horizontal', prob=0.5, type='RandomFlip'),\n",
      "            dict(\n",
      "                brightness=0.12549019607843137,\n",
      "                contrast=0.5,\n",
      "                op='ColorJitter',\n",
      "                saturation=0.5,\n",
      "                type='TorchVisionWrapper'),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackTextDetInputs'),\n",
      "        ],\n",
      "        type='OCRDataset'),\n",
      "    num_workers=24,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='LoadOCRAnnotations',\n",
      "        with_bbox=True,\n",
      "        with_label=True,\n",
      "        with_polygon=True),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.75,\n",
      "            2.5,\n",
      "        ),\n",
      "        scale=(\n",
      "            800,\n",
      "            800,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(\n",
      "        crop_ratio=0.5,\n",
      "        iter_num=1,\n",
      "        min_area_ratio=0.2,\n",
      "        type='TextDetRandomCropFlip'),\n",
      "    dict(\n",
      "        prob=0.8,\n",
      "        transforms=[\n",
      "            dict(min_side_ratio=0.3, type='RandomCrop'),\n",
      "        ],\n",
      "        type='RandomApply'),\n",
      "    dict(\n",
      "        prob=0.5,\n",
      "        transforms=[\n",
      "            dict(\n",
      "                max_angle=30,\n",
      "                pad_with_fixed_color=False,\n",
      "                type='RandomRotate',\n",
      "                use_canvas=True),\n",
      "        ],\n",
      "        type='RandomApply'),\n",
      "    dict(\n",
      "        prob=[\n",
      "            0.6,\n",
      "            0.4,\n",
      "        ],\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale=800, type='Resize'),\n",
      "                dict(target_scale=800, type='SourceImagePad'),\n",
      "            ],\n",
      "            dict(keep_ratio=False, scale=800, type='Resize'),\n",
      "        ],\n",
      "        type='RandomChoice'),\n",
      "    dict(direction='horizontal', prob=0.5, type='RandomFlip'),\n",
      "    dict(\n",
      "        brightness=0.12549019607843137,\n",
      "        contrast=0.5,\n",
      "        op='ColorJitter',\n",
      "        saturation=0.5,\n",
      "        type='TorchVisionWrapper'),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackTextDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='textdet_test.json',\n",
      "        data_root='data/paddleann',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                color_type='color_ignore_orientation',\n",
      "                type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1080,\n",
      "                736,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                type='LoadOCRAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_label=True,\n",
      "                with_polygon=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackTextDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='OCRDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(type='HmeanIOUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='TextDetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/fcenet_resnet50-oclip_fpn_1500e_ctw1500'\n",
      "\n",
      "11/08 16:45:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "11/08 16:45:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: weights/fcenet_resnet50-oclip_fpn_1500e_ctw1500_20221102_121909-101df7e6.pth\n",
      "11/08 16:45:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from weights/fcenet_resnet50-oclip_fpn_1500e_ctw1500_20221102_121909-101df7e6.pth\n",
      "11/08 16:45:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [  5/203]    eta: 0:01:40  time: 0.5100  data_time: 0.0253  memory: 228  \n",
      "11/08 16:45:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 10/203]    eta: 0:01:31  time: 0.4754  data_time: 0.0147  memory: 256  \n",
      "11/08 16:45:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 15/203]    eta: 0:01:22  time: 0.4049  data_time: 0.0042  memory: 267  \n",
      "11/08 16:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 20/203]    eta: 0:01:13  time: 0.3269  data_time: 0.0036  memory: 256  \n",
      "11/08 16:45:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 25/203]    eta: 0:01:38  time: 0.7225  data_time: 0.0029  memory: 271  \n",
      "11/08 16:45:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 30/203]    eta: 0:01:30  time: 0.7727  data_time: 0.0027  memory: 267  \n",
      "11/08 16:45:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 35/203]    eta: 0:01:37  time: 0.6519  data_time: 0.0031  memory: 227  \n",
      "11/08 16:46:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 40/203]    eta: 0:01:36  time: 0.7952  data_time: 0.0032  memory: 249  \n",
      "11/08 16:46:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 45/203]    eta: 0:01:38  time: 0.7765  data_time: 0.0028  memory: 241  \n",
      "11/08 16:46:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 50/203]    eta: 0:01:34  time: 0.7129  data_time: 0.0030  memory: 247  \n",
      "11/08 16:46:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 55/203]    eta: 0:01:27  time: 0.4263  data_time: 0.0028  memory: 267  \n",
      "11/08 16:46:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 60/203]    eta: 0:01:25  time: 0.5042  data_time: 0.0025  memory: 271  \n",
      "11/08 16:46:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 65/203]    eta: 0:01:23  time: 0.7082  data_time: 0.0028  memory: 234  \n",
      "11/08 16:46:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 70/203]    eta: 0:01:18  time: 0.5435  data_time: 0.0030  memory: 263  \n",
      "11/08 16:46:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 75/203]    eta: 0:01:16  time: 0.5226  data_time: 0.0028  memory: 257  \n",
      "11/08 16:46:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 80/203]    eta: 0:01:14  time: 0.7341  data_time: 0.0029  memory: 271  \n",
      "11/08 16:46:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 85/203]    eta: 0:01:10  time: 0.6435  data_time: 0.0032  memory: 242  \n",
      "11/08 16:46:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 90/203]    eta: 0:01:06  time: 0.3981  data_time: 0.0028  memory: 267  \n",
      "11/08 16:46:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 95/203]    eta: 0:01:01  time: 0.3348  data_time: 0.0024  memory: 256  \n",
      "11/08 16:46:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [100/203]    eta: 0:00:58  time: 0.4385  data_time: 0.0023  memory: 271  \n",
      "11/08 16:46:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [105/203]    eta: 0:00:55  time: 0.4567  data_time: 0.0023  memory: 263  \n",
      "11/08 16:46:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [110/203]    eta: 0:00:51  time: 0.3844  data_time: 0.0025  memory: 267  \n",
      "11/08 16:46:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [115/203]    eta: 0:00:47  time: 0.3642  data_time: 0.0028  memory: 256  \n",
      "11/08 16:46:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [120/203]    eta: 0:00:44  time: 0.3873  data_time: 0.0033  memory: 271  \n",
      "11/08 16:46:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [125/203]    eta: 0:00:41  time: 0.4353  data_time: 0.0029  memory: 267  \n",
      "11/08 16:46:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [130/203]    eta: 0:00:40  time: 0.6521  data_time: 0.0027  memory: 271  \n",
      "11/08 16:46:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [135/203]    eta: 0:00:36  time: 0.5837  data_time: 0.0028  memory: 233  \n",
      "11/08 16:46:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [140/203]    eta: 0:00:34  time: 0.5495  data_time: 0.0027  memory: 249  \n",
      "11/08 16:46:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [145/203]    eta: 0:00:31  time: 0.6291  data_time: 0.0026  memory: 271  \n",
      "11/08 16:47:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [150/203]    eta: 0:00:29  time: 0.6169  data_time: 0.0027  memory: 233  \n",
      "11/08 16:47:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [155/203]    eta: 0:00:26  time: 0.7669  data_time: 0.0031  memory: 261  \n",
      "11/08 16:47:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [160/203]    eta: 0:00:24  time: 0.7413  data_time: 0.0029  memory: 263  \n",
      "11/08 16:47:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [165/203]    eta: 0:00:21  time: 0.5053  data_time: 0.0027  memory: 257  \n",
      "11/08 16:47:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [170/203]    eta: 0:00:18  time: 0.5158  data_time: 0.0026  memory: 257  \n",
      "11/08 16:47:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [175/203]    eta: 0:00:15  time: 0.5266  data_time: 0.0035  memory: 257  \n",
      "11/08 16:47:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [180/203]    eta: 0:00:12  time: 0.6161  data_time: 0.0039  memory: 257  \n",
      "11/08 16:47:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [185/203]    eta: 0:00:10  time: 0.7387  data_time: 0.0029  memory: 257  \n",
      "11/08 16:47:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [190/203]    eta: 0:00:07  time: 0.5191  data_time: 0.0027  memory: 257  \n",
      "11/08 16:47:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [195/203]    eta: 0:00:04  time: 0.5480  data_time: 0.0026  memory: 227  \n",
      "11/08 16:47:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [200/203]    eta: 0:00:01  time: 0.5136  data_time: 0.0028  memory: 249  \n",
      "11/08 16:47:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating hmean-iou...\n",
      "11/08 16:47:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.30, recall: 0.1717, precision: 0.4051, hmean: 0.2411\n",
      "\n",
      "11/08 16:47:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.40, recall: 0.1712, precision: 0.4115, hmean: 0.2418\n",
      "\n",
      "11/08 16:47:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.50, recall: 0.1704, precision: 0.4169, hmean: 0.2419\n",
      "\n",
      "11/08 16:47:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.60, recall: 0.1697, precision: 0.4211, hmean: 0.2420\n",
      "\n",
      "11/08 16:47:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.70, recall: 0.1688, precision: 0.4283, hmean: 0.2421\n",
      "\n",
      "11/08 16:47:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.80, recall: 0.1673, precision: 0.4378, hmean: 0.2421\n",
      "\n",
      "11/08 16:47:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.90, recall: 0.1620, precision: 0.4508, hmean: 0.2384\n",
      "\n",
      "11/08 16:47:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [203/203]    icdar/precision: 0.4283  icdar/recall: 0.1688  icdar/hmean: 0.2421  data_time: 0.0035  time: 0.5591\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python tools/test.py configs/textdet/fcenet/fcenet_resnet50-oclip_fpn_1500e_ctw1500.py weights/fcenet_resnet50-oclip_fpn_1500e_ctw1500_20221102_121909-101df7e6.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/13 15:24:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.8.20 (default, Sep  7 2024, 18:35:07) [GCC 13.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 221297894\n",
      "    GPU 0: NVIDIA GeForce GTX 1650\n",
      "    CUDA_HOME: /usr\n",
      "    NVCC: Cuda compilation tools, release 12.0, V12.0.140\n",
      "    GCC: x86_64-linux-gnu-gcc (Ubuntu 13.2.0-23ubuntu4) 13.2.0\n",
      "    PyTorch: 1.10.0+cu111\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.0.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "    TorchVision: 0.11.0+cu111\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 221297894\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "11/13 15:24:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=4)\n",
      "ctw1500_textdet_data_root = 'data/paddleann'\n",
      "ctw1500_textdet_test = dict(\n",
      "    ann_file='textdet_test.json',\n",
      "    data_root='data/paddleann',\n",
      "    pipeline=[\n",
      "        dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),\n",
      "        dict(keep_ratio=True, scale=(\n",
      "            1333,\n",
      "            736,\n",
      "        ), type='Resize'),\n",
      "        dict(\n",
      "            type='LoadOCRAnnotations',\n",
      "            with_bbox=True,\n",
      "            with_label=True,\n",
      "            with_polygon=True),\n",
      "        dict(\n",
      "            meta_keys=(\n",
      "                'img_path',\n",
      "                'ori_shape',\n",
      "                'img_shape',\n",
      "                'scale_factor',\n",
      "            ),\n",
      "            type='PackTextDetInputs'),\n",
      "    ],\n",
      "    test_mode=True,\n",
      "    type='OCRDataset')\n",
      "ctw1500_textdet_train = dict(\n",
      "    ann_file='textdet_test.json',\n",
      "    data_root='data/paddleann',\n",
      "    filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "    pipeline=[\n",
      "        dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),\n",
      "        dict(\n",
      "            type='LoadOCRAnnotations',\n",
      "            with_bbox=True,\n",
      "            with_label=True,\n",
      "            with_polygon=True),\n",
      "        dict(\n",
      "            brightness=0.12549019607843137,\n",
      "            op='ColorJitter',\n",
      "            saturation=0.5,\n",
      "            type='TorchVisionWrapper'),\n",
      "        dict(\n",
      "            prob=0.65,\n",
      "            transforms=[\n",
      "                dict(min_side_ratio=0.3, type='RandomCrop'),\n",
      "            ],\n",
      "            type='RandomApply'),\n",
      "        dict(\n",
      "            max_angle=20,\n",
      "            pad_with_fixed_color=False,\n",
      "            type='RandomRotate',\n",
      "            use_canvas=True),\n",
      "        dict(\n",
      "            aspect_ratio_range=(\n",
      "                0.9,\n",
      "                1.1,\n",
      "            ),\n",
      "            long_size_bound=800,\n",
      "            ratio_range=(\n",
      "                0.7,\n",
      "                1.3,\n",
      "            ),\n",
      "            short_size_bound=480,\n",
      "            type='BoundedScaleAspectJitter'),\n",
      "        dict(\n",
      "            prob=[\n",
      "                0.4,\n",
      "                0.6,\n",
      "            ],\n",
      "            transforms=[\n",
      "                [\n",
      "                    dict(keep_ratio=True, scale=800, type='Resize'),\n",
      "                    dict(target_scale=800, type='SourceImagePad'),\n",
      "                ],\n",
      "                dict(keep_ratio=False, scale=800, type='Resize'),\n",
      "            ],\n",
      "            type='RandomChoice'),\n",
      "        dict(direction='horizontal', prob=0.5, type='RandomFlip'),\n",
      "        dict(\n",
      "            meta_keys=(\n",
      "                'img_path',\n",
      "                'ori_shape',\n",
      "                'img_shape',\n",
      "            ),\n",
      "            type='PackTextDetInputs'),\n",
      "    ],\n",
      "    type='OCRDataset')\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=20, type='CheckpointHook'),\n",
      "    logger=dict(interval=5, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffer=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(\n",
      "        draw_gt=False,\n",
      "        draw_pred=False,\n",
      "        enable=False,\n",
      "        interval=1,\n",
      "        show=False,\n",
      "        type='VisualizationHook'))\n",
      "default_scope = 'mmocr'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "launcher = 'none'\n",
      "load_from = 'weights/textsnake_resnet50-oclip_fpn-unet_1200e_ctw1500_20221101_134814-a216e5b2.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=10)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmocr/backbone/resnet50-oclip-7ba0c533.pth',\n",
      "            type='Pretrained'),\n",
      "        type='CLIPResNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='TextDetDataPreprocessor'),\n",
      "    det_head=dict(\n",
      "        in_channels=32,\n",
      "        module_loss=dict(type='TextSnakeModuleLoss'),\n",
      "        postprocessor=dict(\n",
      "            text_repr_type='poly', type='TextSnakePostprocessor'),\n",
      "        type='TextSnakeHead'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ], out_channels=32, type='FPN_UNet'),\n",
      "    type='TextSnake')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.007, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(end=1200, eta_min=1e-07, power=0.9, type='PolyLR'),\n",
      "]\n",
      "randomness = dict(seed=None)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='textdet_test.json',\n",
      "        data_root='data/paddleann',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                color_type='color_ignore_orientation',\n",
      "                type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                736,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                type='LoadOCRAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_label=True,\n",
      "                with_polygon=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackTextDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='OCRDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(type='HmeanIOUMetric')\n",
      "test_pipeline = [\n",
      "    dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        736,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        type='LoadOCRAnnotations',\n",
      "        with_bbox=True,\n",
      "        with_label=True,\n",
      "        with_polygon=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackTextDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1200, type='EpochBasedTrainLoop', val_interval=20)\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file='textdet_test.json',\n",
      "        data_root='data/paddleann',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                color_type='color_ignore_orientation',\n",
      "                type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='LoadOCRAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_label=True,\n",
      "                with_polygon=True),\n",
      "            dict(\n",
      "                brightness=0.12549019607843137,\n",
      "                op='ColorJitter',\n",
      "                saturation=0.5,\n",
      "                type='TorchVisionWrapper'),\n",
      "            dict(\n",
      "                prob=0.65,\n",
      "                transforms=[\n",
      "                    dict(min_side_ratio=0.3, type='RandomCrop'),\n",
      "                ],\n",
      "                type='RandomApply'),\n",
      "            dict(\n",
      "                max_angle=20,\n",
      "                pad_with_fixed_color=False,\n",
      "                type='RandomRotate',\n",
      "                use_canvas=True),\n",
      "            dict(\n",
      "                aspect_ratio_range=(\n",
      "                    0.9,\n",
      "                    1.1,\n",
      "                ),\n",
      "                long_size_bound=800,\n",
      "                ratio_range=(\n",
      "                    0.7,\n",
      "                    1.3,\n",
      "                ),\n",
      "                short_size_bound=480,\n",
      "                type='BoundedScaleAspectJitter'),\n",
      "            dict(\n",
      "                prob=[\n",
      "                    0.4,\n",
      "                    0.6,\n",
      "                ],\n",
      "                transforms=[\n",
      "                    [\n",
      "                        dict(keep_ratio=True, scale=800, type='Resize'),\n",
      "                        dict(target_scale=800, type='SourceImagePad'),\n",
      "                    ],\n",
      "                    dict(keep_ratio=False, scale=800, type='Resize'),\n",
      "                ],\n",
      "                type='RandomChoice'),\n",
      "            dict(direction='horizontal', prob=0.5, type='RandomFlip'),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                ),\n",
      "                type='PackTextDetInputs'),\n",
      "        ],\n",
      "        type='OCRDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='LoadOCRAnnotations',\n",
      "        with_bbox=True,\n",
      "        with_label=True,\n",
      "        with_polygon=True),\n",
      "    dict(\n",
      "        brightness=0.12549019607843137,\n",
      "        op='ColorJitter',\n",
      "        saturation=0.5,\n",
      "        type='TorchVisionWrapper'),\n",
      "    dict(\n",
      "        prob=0.65,\n",
      "        transforms=[\n",
      "            dict(min_side_ratio=0.3, type='RandomCrop'),\n",
      "        ],\n",
      "        type='RandomApply'),\n",
      "    dict(\n",
      "        max_angle=20,\n",
      "        pad_with_fixed_color=False,\n",
      "        type='RandomRotate',\n",
      "        use_canvas=True),\n",
      "    dict(\n",
      "        aspect_ratio_range=(\n",
      "            0.9,\n",
      "            1.1,\n",
      "        ),\n",
      "        long_size_bound=800,\n",
      "        ratio_range=(\n",
      "            0.7,\n",
      "            1.3,\n",
      "        ),\n",
      "        short_size_bound=480,\n",
      "        type='BoundedScaleAspectJitter'),\n",
      "    dict(\n",
      "        prob=[\n",
      "            0.4,\n",
      "            0.6,\n",
      "        ],\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale=800, type='Resize'),\n",
      "                dict(target_scale=800, type='SourceImagePad'),\n",
      "            ],\n",
      "            dict(keep_ratio=False, scale=800, type='Resize'),\n",
      "        ],\n",
      "        type='RandomChoice'),\n",
      "    dict(direction='horizontal', prob=0.5, type='RandomFlip'),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "        ),\n",
      "        type='PackTextDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='textdet_test.json',\n",
      "        data_root='data/paddleann',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                color_type='color_ignore_orientation',\n",
      "                type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                736,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                type='LoadOCRAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_label=True,\n",
      "                with_polygon=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackTextDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='OCRDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(type='HmeanIOUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='TextDetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/textsnake_resnet50-oclip_fpn-unet_1200e_ctw1500'\n",
      "\n",
      "11/13 15:24:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "11/13 15:24:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: weights/textsnake_resnet50-oclip_fpn-unet_1200e_ctw1500_20221101_134814-a216e5b2.pth\n",
      "11/13 15:24:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from weights/textsnake_resnet50-oclip_fpn-unet_1200e_ctw1500_20221101_134814-a216e5b2.pth\n",
      "11/13 15:24:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [  5/203]    eta: 0:01:58  time: 0.5979  data_time: 0.0256  memory: 996  \n",
      "11/13 15:24:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 10/203]    eta: 0:01:38  time: 0.5111  data_time: 0.0139  memory: 996  \n",
      "11/13 15:24:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 15/203]    eta: 0:01:30  time: 0.4269  data_time: 0.0024  memory: 1002  \n",
      "11/13 15:24:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 20/203]    eta: 0:01:29  time: 0.4698  data_time: 0.0027  memory: 996  \n",
      "11/13 15:24:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 25/203]    eta: 0:01:56  time: 0.9158  data_time: 0.0028  memory: 1011  \n",
      "11/13 15:24:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 30/203]    eta: 0:01:51  time: 0.9465  data_time: 0.0027  memory: 987  \n",
      "11/13 15:24:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 35/203]    eta: 0:01:53  time: 0.7178  data_time: 0.0033  memory: 996  \n",
      "11/13 15:24:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 40/203]    eta: 0:01:56  time: 0.9239  data_time: 0.0032  memory: 1011  \n",
      "11/13 15:24:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 45/203]    eta: 0:02:01  time: 1.0969  data_time: 0.0028  memory: 1003  \n",
      "11/13 15:24:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 50/203]    eta: 0:02:00  time: 1.0943  data_time: 0.0032  memory: 996  \n",
      "11/13 15:24:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 55/203]    eta: 0:01:59  time: 0.9902  data_time: 0.0029  memory: 1011  \n",
      "11/13 15:24:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 60/203]    eta: 0:02:00  time: 1.1053  data_time: 0.0027  memory: 1011  \n",
      "11/13 15:25:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 65/203]    eta: 0:01:55  time: 0.9869  data_time: 0.0026  memory: 1003  \n",
      "11/13 15:25:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 70/203]    eta: 0:01:47  time: 0.6274  data_time: 0.0024  memory: 542  \n",
      "11/13 15:25:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 75/203]    eta: 0:01:45  time: 0.7507  data_time: 0.0024  memory: 998  \n",
      "11/13 15:25:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 80/203]    eta: 0:01:45  time: 1.1878  data_time: 0.0027  memory: 996  \n",
      "11/13 15:25:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 85/203]    eta: 0:01:39  time: 1.0192  data_time: 0.0026  memory: 1011  \n",
      "11/13 15:25:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 90/203]    eta: 0:01:34  time: 0.6629  data_time: 0.0027  memory: 996  \n",
      "11/13 15:25:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 95/203]    eta: 0:01:28  time: 0.5938  data_time: 0.0027  memory: 996  \n",
      "11/13 15:25:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [100/203]    eta: 0:01:24  time: 0.6479  data_time: 0.0030  memory: 996  \n",
      "11/13 15:25:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [105/203]    eta: 0:01:19  time: 0.7278  data_time: 0.0033  memory: 996  \n",
      "11/13 15:25:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [110/203]    eta: 0:01:14  time: 0.6737  data_time: 0.0030  memory: 996  \n",
      "11/13 15:25:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [115/203]    eta: 0:01:09  time: 0.5730  data_time: 0.0028  memory: 917  \n",
      "11/13 15:25:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [120/203]    eta: 0:01:05  time: 0.5476  data_time: 0.0026  memory: 996  \n",
      "11/13 15:25:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [125/203]    eta: 0:01:01  time: 0.7263  data_time: 0.0028  memory: 996  \n",
      "11/13 15:25:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [130/203]    eta: 0:00:58  time: 1.0632  data_time: 0.0031  memory: 998  \n",
      "11/13 15:25:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [135/203]    eta: 0:00:54  time: 1.0656  data_time: 0.0031  memory: 996  \n",
      "11/13 15:26:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [140/203]    eta: 0:00:51  time: 0.8998  data_time: 0.0028  memory: 1007  \n",
      "11/13 15:26:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [145/203]    eta: 0:00:47  time: 0.8950  data_time: 0.0030  memory: 1003  \n",
      "11/13 15:26:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [150/203]    eta: 0:00:43  time: 0.9576  data_time: 0.0031  memory: 996  \n",
      "11/13 15:26:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [155/203]    eta: 0:00:39  time: 1.0395  data_time: 0.0029  memory: 488  \n",
      "11/13 15:26:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [160/203]    eta: 0:00:35  time: 0.9723  data_time: 0.0029  memory: 996  \n",
      "11/13 15:26:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [165/203]    eta: 0:00:31  time: 0.7088  data_time: 0.0026  memory: 542  \n",
      "11/13 15:26:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [170/203]    eta: 0:00:27  time: 0.7599  data_time: 0.0025  memory: 554  \n",
      "11/13 15:26:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [175/203]    eta: 0:00:22  time: 0.7778  data_time: 0.0027  memory: 996  \n",
      "11/13 15:26:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [180/203]    eta: 0:00:19  time: 0.9113  data_time: 0.0028  memory: 994  \n",
      "11/13 15:26:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [185/203]    eta: 0:00:14  time: 1.0870  data_time: 0.0028  memory: 998  \n",
      "11/13 15:26:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [190/203]    eta: 0:00:10  time: 0.8231  data_time: 0.0026  memory: 1002  \n",
      "11/13 15:26:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [195/203]    eta: 0:00:06  time: 0.8082  data_time: 0.0026  memory: 996  \n",
      "11/13 15:26:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [200/203]    eta: 0:00:02  time: 0.8312  data_time: 0.0027  memory: 1007  \n",
      "11/13 15:26:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating hmean-iou...\n",
      "11/13 15:26:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.30, recall: 0.1622, precision: 0.3498, hmean: 0.2216\n",
      "\n",
      "11/13 15:26:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.40, recall: 0.1601, precision: 0.3708, hmean: 0.2237\n",
      "\n",
      "11/13 15:26:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.50, recall: 0.1579, precision: 0.3858, hmean: 0.2241\n",
      "\n",
      "11/13 15:26:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.60, recall: 0.1534, precision: 0.3975, hmean: 0.2214\n",
      "\n",
      "11/13 15:26:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.70, recall: 0.1432, precision: 0.3991, hmean: 0.2107\n",
      "\n",
      "11/13 15:26:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.80, recall: 0.1174, precision: 0.3911, hmean: 0.1806\n",
      "\n",
      "11/13 15:26:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - prediction score threshold: 0.90, recall: 0.0133, precision: 0.1755, hmean: 0.0247\n",
      "\n",
      "11/13 15:26:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [203/203]    icdar/precision: 0.3858  icdar/recall: 0.1579  icdar/hmean: 0.2241  data_time: 0.0034  time: 0.8290\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python tools/test.py configs/textdet/textsnake/textsnake_resnet50-oclip_fpn-unet_1200e_ctw1500.py \\\n",
    "                                             weights/textsnake_resnet50-oclip_fpn-unet_1200e_ctw1500_20221101_134814-a216e5b2.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/diego/p_workspace/mo/lib/python3.8/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "11/15 12:00:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.8.20 (default, Sep  7 2024, 18:35:07) [GCC 13.2.0]\n",
      "    CUDA available: False\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 727122698\n",
      "    GCC: x86_64-linux-gnu-gcc (Ubuntu 13.2.0-23ubuntu4) 13.2.0\n",
      "    PyTorch: 1.10.0+cu111\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "    TorchVision: 0.11.0+cu111\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 727122698\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "11/15 12:00:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=3072)\n",
      "cocotextv1_textrecog_data_root = 'data/rec/coco_text_v1'\n",
      "cocotextv1_textrecog_train = dict(\n",
      "    ann_file='train_labels.json',\n",
      "    data_root='data/rec/coco_text_v1',\n",
      "    pipeline=None,\n",
      "    test_mode=False,\n",
      "    type='OCRDataset')\n",
      "cute80_textrecog_data_root = 'data/cute80'\n",
      "cute80_textrecog_test = dict(\n",
      "    ann_file='textrecog_test.json',\n",
      "    data_root='data/cute80',\n",
      "    pipeline=None,\n",
      "    test_mode=True,\n",
      "    type='OCRDataset')\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffer=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(\n",
      "        draw_gt=False,\n",
      "        draw_pred=False,\n",
      "        enable=False,\n",
      "        interval=1,\n",
      "        show=False,\n",
      "        type='VisualizationHook'))\n",
      "default_scope = 'mmocr'\n",
      "dictionary = dict(\n",
      "    dict_file=\n",
      "    '/home/diego/p_workspace/mmocr/configs/textrecog/sar/../../../dicts/english_digits_symbols.txt',\n",
      "    same_start_end=True,\n",
      "    type='Dictionary',\n",
      "    with_end=True,\n",
      "    with_padding=True,\n",
      "    with_start=True,\n",
      "    with_unknown=True)\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "icdar2011_textrecog_data_root = 'data/rec/icdar_2011/'\n",
      "icdar2011_textrecog_train = dict(\n",
      "    ann_file='train_labels.json',\n",
      "    data_root='data/rec/icdar_2011/',\n",
      "    pipeline=None,\n",
      "    test_mode=False,\n",
      "    type='OCRDataset')\n",
      "icdar2013_857_textrecog_test = dict(\n",
      "    ann_file='textrecog_test_857.json',\n",
      "    data_root='data/icdar2013',\n",
      "    pipeline=None,\n",
      "    test_mode=True,\n",
      "    type='OCRDataset')\n",
      "icdar2013_textrecog_data_root = 'data/icdar2013'\n",
      "icdar2013_textrecog_test = dict(\n",
      "    ann_file='textrecog_test.json',\n",
      "    data_root='data/icdar2013',\n",
      "    pipeline=None,\n",
      "    test_mode=True,\n",
      "    type='OCRDataset')\n",
      "icdar2013_textrecog_train = dict(\n",
      "    ann_file='textrecog_train.json',\n",
      "    data_root='data/icdar2013',\n",
      "    pipeline=None,\n",
      "    type='OCRDataset')\n",
      "icdar2015_1811_textrecog_test = dict(\n",
      "    ann_file='textrecog_test_1811.json',\n",
      "    data_root='data/icdar2015',\n",
      "    pipeline=None,\n",
      "    test_mode=True,\n",
      "    type='OCRDataset')\n",
      "icdar2015_textrecog_data_root = 'data/icdar2015'\n",
      "icdar2015_textrecog_test = dict(\n",
      "    ann_file='textrecog_test.json',\n",
      "    data_root='data/icdar2015',\n",
      "    pipeline=None,\n",
      "    test_mode=True,\n",
      "    type='OCRDataset')\n",
      "icdar2015_textrecog_train = dict(\n",
      "    ann_file='textrecog_train.json',\n",
      "    data_root='data/icdar2015',\n",
      "    pipeline=None,\n",
      "    type='OCRDataset')\n",
      "iiit5k_textrecog_data_root = 'data/iiit5k'\n",
      "iiit5k_textrecog_test = dict(\n",
      "    ann_file='textrecog_test.json',\n",
      "    data_root='data/iiit5k',\n",
      "    pipeline=None,\n",
      "    test_mode=True,\n",
      "    type='OCRDataset')\n",
      "iiit5k_textrecog_train = dict(\n",
      "    ann_file='textrecog_train.json',\n",
      "    data_root='data/iiit5k',\n",
      "    pipeline=None,\n",
      "    type='OCRDataset')\n",
      "launcher = 'none'\n",
      "load_from = 'weights/sar_resnet31_parallel-decoder_5e_st-sub_mj-sub_sa_real_20220915_171910-04eb4e75.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=10)\n",
      "mjsynth_sub_textrecog_train = dict(\n",
      "    ann_file='subset_textrecog_train.json',\n",
      "    data_root='data/mjsynth',\n",
      "    pipeline=None,\n",
      "    type='OCRDataset')\n",
      "mjsynth_textrecog_data_root = 'data/mjsynth'\n",
      "mjsynth_textrecog_train = dict(\n",
      "    ann_file='textrecog_train.json',\n",
      "    data_root='data/mjsynth',\n",
      "    pipeline=None,\n",
      "    type='OCRDataset')\n",
      "model = dict(\n",
      "    backbone=dict(type='ResNet31OCR'),\n",
      "    data_preprocessor=dict(\n",
      "        mean=[\n",
      "            127,\n",
      "            127,\n",
      "            127,\n",
      "        ],\n",
      "        std=[\n",
      "            127,\n",
      "            127,\n",
      "            127,\n",
      "        ],\n",
      "        type='TextRecogDataPreprocessor'),\n",
      "    decoder=dict(\n",
      "        d_k=512,\n",
      "        dec_bi_rnn=False,\n",
      "        dec_do_rnn=0,\n",
      "        dec_gru=False,\n",
      "        dictionary=dict(\n",
      "            dict_file=\n",
      "            '/home/diego/p_workspace/mmocr/configs/textrecog/sar/../../../dicts/english_digits_symbols.txt',\n",
      "            same_start_end=True,\n",
      "            type='Dictionary',\n",
      "            with_end=True,\n",
      "            with_padding=True,\n",
      "            with_start=True,\n",
      "            with_unknown=True),\n",
      "        enc_bi_rnn=False,\n",
      "        max_seq_len=30,\n",
      "        module_loss=dict(\n",
      "            ignore_first_char=True, reduction='mean', type='CEModuleLoss'),\n",
      "        postprocessor=dict(type='AttentionPostprocessor'),\n",
      "        pred_concat=True,\n",
      "        pred_dropout=0.1,\n",
      "        type='ParallelSARDecoder'),\n",
      "    encoder=dict(\n",
      "        enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False, type='SAREncoder'),\n",
      "    type='SARNet')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.001, type='Adam'), type='OptimWrapper')\n",
      "paddleann_textrecog_data_root = 'data/paddleann'\n",
      "paddleann_textrecog_test = dict(\n",
      "    ann_file='textrecog_test.json',\n",
      "    data_root='data/paddleann',\n",
      "    pipeline=None,\n",
      "    test_mode=True,\n",
      "    type='OCRDataset')\n",
      "paddleann_textrecog_train = dict(\n",
      "    ann_file='textrecog_test.json',\n",
      "    data_root='data/paddleann',\n",
      "    pipeline=None,\n",
      "    type='OCRDataset')\n",
      "param_scheduler = [\n",
      "    dict(end=5, milestones=[\n",
      "        3,\n",
      "        4,\n",
      "    ], type='MultiStepLR'),\n",
      "]\n",
      "randomness = dict(seed=None)\n",
      "resume = False\n",
      "svt_textrecog_data_root = 'data/svt'\n",
      "svt_textrecog_test = dict(\n",
      "    ann_file='textrecog_test.json',\n",
      "    data_root='data/svt',\n",
      "    pipeline=None,\n",
      "    test_mode=True,\n",
      "    type='OCRDataset')\n",
      "svt_textrecog_train = dict(\n",
      "    ann_file='textrecog_train.json',\n",
      "    data_root='data/svt',\n",
      "    pipeline=None,\n",
      "    type='OCRDataset')\n",
      "svtp_textrecog_data_root = 'data/svtp'\n",
      "svtp_textrecog_test = dict(\n",
      "    ann_file='textrecog_test.json',\n",
      "    data_root='data/svtp',\n",
      "    pipeline=None,\n",
      "    test_mode=True,\n",
      "    type='OCRDataset')\n",
      "svtp_textrecog_train = dict(\n",
      "    ann_file='textrecog_train.json',\n",
      "    data_root='data/svtp',\n",
      "    pipeline=None,\n",
      "    type='OCRDataset')\n",
      "synthtext_add_textrecog_data_root = 'data/rec/synthtext_add/'\n",
      "synthtext_add_textrecog_train = dict(\n",
      "    ann_file='train_labels.json',\n",
      "    data_root='data/rec/synthtext_add/',\n",
      "    pipeline=None,\n",
      "    test_mode=False,\n",
      "    type='OCRDataset')\n",
      "synthtext_an_textrecog_train = dict(\n",
      "    ann_file='alphanumeric_textrecog_train.json',\n",
      "    data_root='data/synthtext',\n",
      "    pipeline=None,\n",
      "    type='OCRDataset')\n",
      "synthtext_sub_textrecog_train = dict(\n",
      "    ann_file='subset_textrecog_train.json',\n",
      "    data_root='data/synthtext',\n",
      "    pipeline=None,\n",
      "    type='OCRDataset')\n",
      "synthtext_textrecog_data_root = 'data/synthtext'\n",
      "synthtext_textrecog_train = dict(\n",
      "    ann_file='textrecog_train.json',\n",
      "    data_root='data/synthtext',\n",
      "    pipeline=None,\n",
      "    type='OCRDataset')\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        datasets=[\n",
      "            dict(\n",
      "                ann_file='textrecog_test.json',\n",
      "                data_root='data/paddleann',\n",
      "                pipeline=None,\n",
      "                test_mode=True,\n",
      "                type='OCRDataset'),\n",
      "        ],\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                height=48,\n",
      "                max_width=160,\n",
      "                min_width=48,\n",
      "                type='RescaleToHeight',\n",
      "                width_divisor=4),\n",
      "            dict(type='PadToWidth', width=160),\n",
      "            dict(type='LoadOCRAnnotations', with_text=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'valid_ratio',\n",
      "                ),\n",
      "                type='PackTextRecogInputs'),\n",
      "        ],\n",
      "        type='ConcatDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    dataset_prefixes=[\n",
      "        'PaddleANN',\n",
      "    ],\n",
      "    metrics=[\n",
      "        dict(\n",
      "            mode=[\n",
      "                'exact',\n",
      "                'ignore_case',\n",
      "                'ignore_case_symbol',\n",
      "            ],\n",
      "            type='WordMetric'),\n",
      "        dict(type='CharMetric'),\n",
      "    ],\n",
      "    type='MultiDatasetsEvaluator')\n",
      "test_list = [\n",
      "    dict(\n",
      "        ann_file='textrecog_test.json',\n",
      "        data_root='data/paddleann',\n",
      "        pipeline=None,\n",
      "        test_mode=True,\n",
      "        type='OCRDataset'),\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        height=48,\n",
      "        max_width=160,\n",
      "        min_width=48,\n",
      "        type='RescaleToHeight',\n",
      "        width_divisor=4),\n",
      "    dict(type='PadToWidth', width=160),\n",
      "    dict(type='LoadOCRAnnotations', with_text=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'valid_ratio',\n",
      "        ),\n",
      "        type='PackTextRecogInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=5, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=384,\n",
      "    dataset=dict(\n",
      "        datasets=[\n",
      "            dict(\n",
      "                dataset=dict(\n",
      "                    datasets=[\n",
      "                        dict(\n",
      "                            ann_file='train_labels.json',\n",
      "                            data_root='data/rec/icdar_2011/',\n",
      "                            pipeline=None,\n",
      "                            test_mode=False,\n",
      "                            type='OCRDataset'),\n",
      "                        dict(\n",
      "                            ann_file='textrecog_train.json',\n",
      "                            data_root='data/icdar2013',\n",
      "                            pipeline=None,\n",
      "                            type='OCRDataset'),\n",
      "                        dict(\n",
      "                            ann_file='textrecog_train.json',\n",
      "                            data_root='data/icdar2015',\n",
      "                            pipeline=None,\n",
      "                            type='OCRDataset'),\n",
      "                        dict(\n",
      "                            ann_file='train_labels.json',\n",
      "                            data_root='data/rec/coco_text_v1',\n",
      "                            pipeline=None,\n",
      "                            test_mode=False,\n",
      "                            type='OCRDataset'),\n",
      "                        dict(\n",
      "                            ann_file='textrecog_train.json',\n",
      "                            data_root='data/iiit5k',\n",
      "                            pipeline=None,\n",
      "                            type='OCRDataset'),\n",
      "                    ],\n",
      "                    pipeline=[\n",
      "                        dict(\n",
      "                            ignore_empty=True,\n",
      "                            min_size=2,\n",
      "                            type='LoadImageFromFile'),\n",
      "                        dict(type='LoadOCRAnnotations', with_text=True),\n",
      "                        dict(\n",
      "                            height=48,\n",
      "                            max_width=160,\n",
      "                            min_width=48,\n",
      "                            type='RescaleToHeight',\n",
      "                            width_divisor=4),\n",
      "                        dict(type='PadToWidth', width=160),\n",
      "                        dict(\n",
      "                            meta_keys=(\n",
      "                                'img_path',\n",
      "                                'ori_shape',\n",
      "                                'img_shape',\n",
      "                                'valid_ratio',\n",
      "                            ),\n",
      "                            type='PackTextRecogInputs'),\n",
      "                    ],\n",
      "                    type='ConcatDataset'),\n",
      "                times=20,\n",
      "                type='RepeatDataset'),\n",
      "            dict(\n",
      "                datasets=[\n",
      "                    dict(\n",
      "                        ann_file='subset_textrecog_train.json',\n",
      "                        data_root='data/mjsynth',\n",
      "                        pipeline=None,\n",
      "                        type='OCRDataset'),\n",
      "                    dict(\n",
      "                        ann_file='subset_textrecog_train.json',\n",
      "                        data_root='data/synthtext',\n",
      "                        pipeline=None,\n",
      "                        type='OCRDataset'),\n",
      "                    dict(\n",
      "                        ann_file='train_labels.json',\n",
      "                        data_root='data/rec/synthtext_add/',\n",
      "                        pipeline=None,\n",
      "                        test_mode=False,\n",
      "                        type='OCRDataset'),\n",
      "                ],\n",
      "                pipeline=[\n",
      "                    dict(\n",
      "                        ignore_empty=True,\n",
      "                        min_size=2,\n",
      "                        type='LoadImageFromFile'),\n",
      "                    dict(type='LoadOCRAnnotations', with_text=True),\n",
      "                    dict(\n",
      "                        height=48,\n",
      "                        max_width=160,\n",
      "                        min_width=48,\n",
      "                        type='RescaleToHeight',\n",
      "                        width_divisor=4),\n",
      "                    dict(type='PadToWidth', width=160),\n",
      "                    dict(\n",
      "                        meta_keys=(\n",
      "                            'img_path',\n",
      "                            'ori_shape',\n",
      "                            'img_shape',\n",
      "                            'valid_ratio',\n",
      "                        ),\n",
      "                        type='PackTextRecogInputs'),\n",
      "                ],\n",
      "                type='ConcatDataset'),\n",
      "        ],\n",
      "        type='ConcatDataset',\n",
      "        verify_meta=False),\n",
      "    num_workers=24,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_list = [\n",
      "    dict(\n",
      "        dataset=dict(\n",
      "            datasets=[\n",
      "                dict(\n",
      "                    ann_file='train_labels.json',\n",
      "                    data_root='data/rec/icdar_2011/',\n",
      "                    pipeline=None,\n",
      "                    test_mode=False,\n",
      "                    type='OCRDataset'),\n",
      "                dict(\n",
      "                    ann_file='textrecog_train.json',\n",
      "                    data_root='data/icdar2013',\n",
      "                    pipeline=None,\n",
      "                    type='OCRDataset'),\n",
      "                dict(\n",
      "                    ann_file='textrecog_train.json',\n",
      "                    data_root='data/icdar2015',\n",
      "                    pipeline=None,\n",
      "                    type='OCRDataset'),\n",
      "                dict(\n",
      "                    ann_file='train_labels.json',\n",
      "                    data_root='data/rec/coco_text_v1',\n",
      "                    pipeline=None,\n",
      "                    test_mode=False,\n",
      "                    type='OCRDataset'),\n",
      "                dict(\n",
      "                    ann_file='textrecog_train.json',\n",
      "                    data_root='data/iiit5k',\n",
      "                    pipeline=None,\n",
      "                    type='OCRDataset'),\n",
      "            ],\n",
      "            pipeline=[\n",
      "                dict(ignore_empty=True, min_size=2, type='LoadImageFromFile'),\n",
      "                dict(type='LoadOCRAnnotations', with_text=True),\n",
      "                dict(\n",
      "                    height=48,\n",
      "                    max_width=160,\n",
      "                    min_width=48,\n",
      "                    type='RescaleToHeight',\n",
      "                    width_divisor=4),\n",
      "                dict(type='PadToWidth', width=160),\n",
      "                dict(\n",
      "                    meta_keys=(\n",
      "                        'img_path',\n",
      "                        'ori_shape',\n",
      "                        'img_shape',\n",
      "                        'valid_ratio',\n",
      "                    ),\n",
      "                    type='PackTextRecogInputs'),\n",
      "            ],\n",
      "            type='ConcatDataset'),\n",
      "        times=20,\n",
      "        type='RepeatDataset'),\n",
      "    dict(\n",
      "        datasets=[\n",
      "            dict(\n",
      "                ann_file='subset_textrecog_train.json',\n",
      "                data_root='data/mjsynth',\n",
      "                pipeline=None,\n",
      "                type='OCRDataset'),\n",
      "            dict(\n",
      "                ann_file='subset_textrecog_train.json',\n",
      "                data_root='data/synthtext',\n",
      "                pipeline=None,\n",
      "                type='OCRDataset'),\n",
      "            dict(\n",
      "                ann_file='train_labels.json',\n",
      "                data_root='data/rec/synthtext_add/',\n",
      "                pipeline=None,\n",
      "                test_mode=False,\n",
      "                type='OCRDataset'),\n",
      "        ],\n",
      "        pipeline=[\n",
      "            dict(ignore_empty=True, min_size=2, type='LoadImageFromFile'),\n",
      "            dict(type='LoadOCRAnnotations', with_text=True),\n",
      "            dict(\n",
      "                height=48,\n",
      "                max_width=160,\n",
      "                min_width=48,\n",
      "                type='RescaleToHeight',\n",
      "                width_divisor=4),\n",
      "            dict(type='PadToWidth', width=160),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'valid_ratio',\n",
      "                ),\n",
      "                type='PackTextRecogInputs'),\n",
      "        ],\n",
      "        type='ConcatDataset'),\n",
      "]\n",
      "train_pipeline = [\n",
      "    dict(ignore_empty=True, min_size=2, type='LoadImageFromFile'),\n",
      "    dict(type='LoadOCRAnnotations', with_text=True),\n",
      "    dict(\n",
      "        height=48,\n",
      "        max_width=160,\n",
      "        min_width=48,\n",
      "        type='RescaleToHeight',\n",
      "        width_divisor=4),\n",
      "    dict(type='PadToWidth', width=160),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'valid_ratio',\n",
      "        ),\n",
      "        type='PackTextRecogInputs'),\n",
      "]\n",
      "tta_model = dict(type='EncoderDecoderRecognizerTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(\n",
      "                    condition=\"results['img_shape'][1]<results['img_shape'][0]\",\n",
      "                    true_transforms=[\n",
      "                        dict(\n",
      "                            args=[\n",
      "                                dict(cls='Rot90', k=0, keep_size=False),\n",
      "                            ],\n",
      "                            type='ImgAugWrapper'),\n",
      "                    ],\n",
      "                    type='ConditionApply'),\n",
      "                dict(\n",
      "                    condition=\"results['img_shape'][1]<results['img_shape'][0]\",\n",
      "                    true_transforms=[\n",
      "                        dict(\n",
      "                            args=[\n",
      "                                dict(cls='Rot90', k=1, keep_size=False),\n",
      "                            ],\n",
      "                            type='ImgAugWrapper'),\n",
      "                    ],\n",
      "                    type='ConditionApply'),\n",
      "                dict(\n",
      "                    condition=\"results['img_shape'][1]<results['img_shape'][0]\",\n",
      "                    true_transforms=[\n",
      "                        dict(\n",
      "                            args=[\n",
      "                                dict(cls='Rot90', k=3, keep_size=False),\n",
      "                            ],\n",
      "                            type='ImgAugWrapper'),\n",
      "                    ],\n",
      "                    type='ConditionApply'),\n",
      "            ],\n",
      "            [\n",
      "                dict(\n",
      "                    height=48,\n",
      "                    max_width=160,\n",
      "                    min_width=48,\n",
      "                    type='RescaleToHeight',\n",
      "                    width_divisor=4),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PadToWidth', width=160),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadOCRAnnotations', with_text=True),\n",
      "            ],\n",
      "            [\n",
      "                dict(\n",
      "                    meta_keys=(\n",
      "                        'img_path',\n",
      "                        'ori_shape',\n",
      "                        'img_shape',\n",
      "                        'valid_ratio',\n",
      "                    ),\n",
      "                    type='PackTextRecogInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        datasets=[\n",
      "            dict(\n",
      "                ann_file='textrecog_test.json',\n",
      "                data_root='data/paddleann',\n",
      "                pipeline=None,\n",
      "                test_mode=True,\n",
      "                type='OCRDataset'),\n",
      "        ],\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                height=48,\n",
      "                max_width=160,\n",
      "                min_width=48,\n",
      "                type='RescaleToHeight',\n",
      "                width_divisor=4),\n",
      "            dict(type='PadToWidth', width=160),\n",
      "            dict(type='LoadOCRAnnotations', with_text=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'valid_ratio',\n",
      "                ),\n",
      "                type='PackTextRecogInputs'),\n",
      "        ],\n",
      "        type='ConcatDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    dataset_prefixes=[\n",
      "        'PaddleANN',\n",
      "    ],\n",
      "    metrics=[\n",
      "        dict(\n",
      "            mode=[\n",
      "                'exact',\n",
      "                'ignore_case',\n",
      "                'ignore_case_symbol',\n",
      "            ],\n",
      "            type='WordMetric'),\n",
      "        dict(type='CharMetric'),\n",
      "    ],\n",
      "    type='MultiDatasetsEvaluator')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='TextRecogLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/sar_resnet31_parallel-decoder_5e_st-sub_mj-sub_sa_real'\n",
      "\n",
      "11/15 12:00:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "11/15 12:00:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: weights/sar_resnet31_parallel-decoder_5e_st-sub_mj-sub_sa_real_20220915_171910-04eb4e75.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n",
      "\n",
      "11/15 12:00:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from weights/sar_resnet31_parallel-decoder_5e_st-sub_mj-sub_sa_real_20220915_171910-04eb4e75.pth\n",
      "11/15 12:04:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 100/6245]    eta: 4:30:36  time: 3.0337  data_time: 0.0035  \n",
      "11/15 12:10:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 200/6245]    eta: 5:00:08  time: 3.3101  data_time: 0.0060  \n",
      "11/15 12:15:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 300/6245]    eta: 5:03:33  time: 3.2549  data_time: 0.0040  \n",
      "11/15 12:21:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 400/6245]    eta: 5:02:49  time: 3.4035  data_time: 0.0043  \n",
      "11/15 12:26:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 500/6245]    eta: 5:00:04  time: 3.2828  data_time: 0.0031  \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/test.py\", line 141, in <module>\n",
      "    main()\n",
      "  File \"tools/test.py\", line 137, in main\n",
      "    runner.test()\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/mmengine/runner/runner.py\", line 1823, in test\n",
      "    metrics = self.test_loop.run()  # type: ignore\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/mmengine/runner/loops.py\", line 463, in run\n",
      "    self.run_iter(idx, data_batch)\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/mmengine/runner/loops.py\", line 487, in run_iter\n",
      "    outputs = self.runner.model.test_step(data_batch)\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py\", line 145, in test_step\n",
      "    return self._run_forward(data, mode='predict')  # type: ignore\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py\", line 361, in _run_forward\n",
      "    results = self(**data, mode=mode)\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/diego/p_workspace/mmocr/mmocr/models/textrecog/recognizers/base.py\", line 90, in forward\n",
      "    return self.predict(inputs, data_samples, **kwargs)\n",
      "  File \"/home/diego/p_workspace/mmocr/mmocr/models/textrecog/recognizers/encoder_decoder_recognizer.py\", line 108, in predict\n",
      "    return self.decoder.predict(feat, out_enc, data_samples)\n",
      "  File \"/home/diego/p_workspace/mmocr/mmocr/models/textrecog/decoders/base.py\", line 138, in predict\n",
      "    out_dec = self(feat, out_enc, data_samples)\n",
      "  File \"/home/diego/p_workspace/mo/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/diego/p_workspace/mmocr/mmocr/models/textrecog/decoders/base.py\", line 166, in forward\n",
      "    return self.forward_test(feat, out_enc, data_samples)\n",
      "  File \"/home/diego/p_workspace/mmocr/mmocr/models/textrecog/decoders/sar_decoder.py\", line 276, in forward_test\n",
      "    decoder_output = self._2d_attention(\n",
      "  File \"/home/diego/p_workspace/mmocr/mmocr/models/textrecog/decoders/sar_decoder.py\", line 156, in _2d_attention\n",
      "    bsz, T, h, w, c = attn_weight.size()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python tools/test.py configs/textrecog/sar/sar_resnet31_parallel-decoder_5e_st-sub_mj-sub_sa_real.py \\\n",
    "                                             weights/sar_resnet31_parallel-decoder_5e_st-sub_mj-sub_sa_real_20220915_171910-04eb4e75.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
